> 引用自 : https://www.cnblogs.com/xiaobaiskill/p/10969180.html
##### nginx 的进程
###### master 进程
 - nginx 创建一个 master 进程, 通过 socket() 创建一个 socket 文件描述符用来监听(sockfd)
 - 绑定端口(bind) 开启监听(listen)
 - 创建(fork)多个子进程(worker)，master 会监听 worker 进程和等待信号
 
###### worker 子进程
 - 子进程(worker)继承了master进程(自然也继承了sockfd\[socket文件描述符\])
 - 当有连接进来之后 worker 进程就可以 accept() 创建已连接描述符.
 - 通过已连接描述符与客户端通信
###### worker主要工作
 1. accept() 与客户端建立连接
 2. recv() 接收客户端发过来的数据
 3. send() 向客户端发送数据
 4. close() 关闭客户端连接
 
###### worker引发的性能问题
 - 与客户端建立连接(accept())后recv() 一直等待客户端发送过来数据(此时IO处于阻塞状态)
 - 此时有其它客户端过来建立连接，那么只能等待，需要一直等待 close() 之后才可以建立连接
 - 以上的逻辑造成了性能的浪费
 
###### IO多路复用
 - IO复用解决的就是并发行的问题，比如多个用户并发访问一个WEB网站，
 对于服务端后台而言就会产生多个请求，处理多个请求对于中间件就会产生多个IO流对于系统的读写。
 那么对于IO流请求操作系统内核有并行处理和串行处理的概念，串行处理的方式是一个个处理，
 前面的发生阻塞，就没办法完成后面的请求。
 这个时候我们必须考虑并行的方式完成整个IO流的请求来实现最大的并发和吞吐，这时候就是用到IO复用技术。
 IO复用就是让一个Socket来作为复用完成整个IO流的请求。当然实现整个IO流的请求多线程的方式就是其中一种。
 - （一个socket作为复用来完成整个io流的请求连接建立(accept)，而处理请求（recv,send,close）则采用多线程）
 > 总而言之， 就是用一个 文件描述符(sockfd)来接收多个前端连接，接收到(accept())前端连接, 就开启一个线程(此时文件描述符(sockfd)就可以去处理其它accept()了)，让线程处理 recv send close 等操作
 
 - 多个描述符(监听描述符，已连接描述符) 的 IO 操作都能在一个线程内并发交替顺序完成, 这就叫 IO多路复用
 
###### IO多路复用的三种机制 select poll epoll
 - select
    + `int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout)`
        - 传给select 需要处理的文件描述符(比如`已连接描述符`)
        - select 通过轮询的方式不断扫描需要处理的文件描述符(扫描间隔时间由 timeval 决定)
        - nfds 为需要监听的最大文件描述符值+1
    + `特点`
        - 可处理的文件描述符数量是有上限的
        - 每次调用 select 之前，都需要重新把需要处理的文件描述符加入 fd_set 中
        
    + `缺点`
        - 每次调用select前都需要重新填充 fd_set
        - select 需要遍历 fd_set集合, 而且要将 fd_set 里的数据拷贝一份到内核中, 如果 fd_set 很多, 开销会很大
        - select 支持的文件描述符数量太少 32位系统-1024 64位系统-2048
 - poll
    + `int poll(struct pollfd *fds, nfds_t nfds, int timeout)`
        - 将要处理的文件描述符放入到以pollfd结构体为单元的fd_list数组中, pollfd结构体中保存文件描述符和要关心的事件、是否就绪事件
        - 调用poll函数需要轮询(遍历)的方式查看fd_list中哪个文件描述符就绪了
        
    + `特点`
        - 每次调用 poll前不需要重新填充 fd_list集合
        - 支持的文件描述符理论上无上限的(其实也有, 一个进程打开的文件数量是有上线的)
    + `缺点`
        - poll 还是会轮询 pd_list 来获取就绪的文件描述符
        - 同时连接的大量客户端，可能只有很少的处于就绪状态，因此随着监事的描述符数量的增长，其效率也会线性下降
        
 - epoll
    + 工作原理
        - 创建一个 epoll 对象, 向 epoll 对象中添加文件描述符以及我们所关心的在该文件描述符上发生的事件
        - 向我们需要关心的文件描述符中注册事件(读 写 异常等), 操作系统将该事件和对象的文件描述符作为一个节点插入到底层建立的红黑树中
        - 添加到文件描述符上的实际都会与网卡建立回调机制, 也就是实际发生时会自主调用的一个回调方法，将事件所在的文件描述符插入到就绪队列中
        - 从所有就绪队列中将所有就绪的文件描述符拿到, 可以说时间复杂度 O(1)
        
        
        
##### 总结
 - nginx 通过 多进程 + io多路复用（epoll） 实现了高并发
 - 采用多个worker 进程实现对 多cpu 的利用
 - 通过eopll 对 多个文件描述符 事件回调机制和就绪描述符的处理 实现单线程io复用从而实现高并发 