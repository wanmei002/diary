## 入口
```go
if c.CpuThreshold > 0 {
	shedder := load.NewAdaptiveShedder(load.WithCpuThreshold(c.CpuThreshold))
	server.AddUnaryInterceptors(serverinterceptors.UnarySheddingInterceptor(shedder, metrics))
}
```

## 第二步
```go
// WithCpuThreshold customizes the Shedder with given cpu threshold.
func WithCpuThreshold(threshold int64) ShedderOption {
	return func(opts *shedderOptions) {
		opts.cpuThreshold = threshold
	}
}

type ShedderOption func(opts *shedderOptions)

type shedderOptions struct {
    window       time.Duration
    buckets      int
    cpuThreshold int64
}
```

## 第三步
```go
func NewAdaptiveShedder(opts ...ShedderOption) Shedder {
	if !enabled.True() {// 不会走这一步
		return newNopShedder()
	}

	options := shedderOptions{
		window:       defaultWindow, // defaultWindow  = time.Second * 5
		buckets:      defaultBuckets, // defaultBuckets = 50
		cpuThreshold: defaultCpuThreshold, // defaultCpuThreshold = 900
	}
	for _, opt := range opts {
		// 这里有一个函数处理  opts.cpuThreshold = threshold
		opt(&options)
	}
	bucketDuration := options.window / time.Duration(options.buckets)
	return &adaptiveShedder{
		cpuThreshold:    options.cpuThreshold,
		windows:         int64(time.Second / bucketDuration),// 10
		dropTime:        syncx.NewAtomicDuration(), // type AtomicDuration int64
		droppedRecently: syncx.NewAtomicBool(),// type AtomicBool uint32
		passCounter: collection.NewRollingWindow(options.buckets, bucketDuration,// 50  second*5/50
			collection.IgnoreCurrentBucket()),
		rtCounter: collection.NewRollingWindow(options.buckets, bucketDuration,
			collection.IgnoreCurrentBucket()),
	}
}
```
上面的 passCounter 属性
```go
func IgnoreCurrentBucket() RollingWindowOption {
	return func(w *RollingWindow) {
		w.ignoreCurrent = true
	}
}
```

上面的 NewRollingWindow 方法
```go
func NewRollingWindow(size int, interval time.Duration, opts ...RollingWindowOption) *RollingWindow {
	if size < 1 {
		panic("size must be greater than 0")
	}

	w := &RollingWindow{
		size:     size,
		win:      newWindow(size),
		interval: interval,
		lastTime: timex.Now(),
	}
	for _, opt := range opts {
		opt(w)
	}
	return w
}

func newWindow(size int) *window {
	buckets := make([]*Bucket, size)
	for i := 0; i < size; i++ {
		buckets[i] = new(Bucket)
	}
	return &window{
		buckets: buckets,
		size:    size,
	}
}

type Bucket struct {
	Sum   float64
	Count int64
}
```

## 开始主要方法
```go
    // 这里主要用的 shedder 接口是这个struct
    // &adaptiveShedder{
    // 		cpuThreshold:    options.cpuThreshold,
    // 		windows:         int64(time.Second / bucketDuration),// 10
    // 		dropTime:        syncx.NewAtomicDuration(), // type AtomicDuration int64
    // 		droppedRecently: syncx.NewAtomicBool(),// type AtomicBool uint32
    // 		passCounter: collection.NewRollingWindow(options.buckets, bucketDuration,// 50  second*5/50
    // 			collection.IgnoreCurrentBucket()),
    // 		rtCounter: collection.NewRollingWindow(options.buckets, bucketDuration,
    // 			collection.IgnoreCurrentBucket()),
    // }
func UnarySheddingInterceptor(shedder load.Shedder, metrics *stat.Metrics) grpc.UnaryServerInterceptor {
	// 这个方法设置了 全局变量sheddingStat = &SheddingStat{name: "rpc"}
	// 同时引入了 cpu 相关的包，这些包里的 init() 方法里用定时器计算cpu负荷
	ensureSheddingStat()

	return func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo,
		handler grpc.UnaryHandler) (val interface{}, err error) {
		// 给 SheddingStat.total 方法加 1
		sheddingStat.IncrementTotal()
		var promise load.Promise
		promise, err = shedder.Allow()
		if err != nil {
			metrics.AddDrop()
			sheddingStat.IncrementDrop()
			return
		}

		defer func() {
			if err == context.DeadlineExceeded {
				promise.Fail()
			} else {
				sheddingStat.IncrementPass()
				promise.Pass()
			}
		}()

		return handler(ctx, req)
	}
}


```

 - Allow() 方法
 ```go
 // Allow implements Shedder.Allow.
 func (as *adaptiveShedder) Allow() (Promise, error) {
 	if as.shouldDrop() {
 		as.dropTime.Set(timex.Now())
 		as.droppedRecently.Set(true)
 
 		return nil, ErrServiceOverloaded
 	}
 
 	as.addFlying(1)
 
 	return &promise{
 		start:   timex.Now(),
 		shedder: as,
 	}, nil
 }
 ```
 + shouldDrop 做的是事情
    先对比 CPU性能, 过载了返回true, 
    然后 查看 adaptiveShedder.droppedRecently 值是否为1.如果为 1,则在检查 adaptiveShedder.dropTime 跟一年前的时间对比是否小于 1秒，
    如果不小于1s 则设置adaptiveShedder.droppedRecently=0，

 - ensureSheddingStat()
    ```go
        func ensureSheddingStat() {
            lock.Lock()
            if sheddingStat == nil {
                sheddingStat = load.NewSheddingStat(serviceType)// const serviceType = "rpc"
            }
            lock.Unlock()
        }
        
        SheddingStat struct {
            name  string
            total int64
            pass  int64
            drop  int64
        }
    ``` 
    - <span id="NewSheddingStat">NewSheddingStat(name string)方法</span>
    ```go
    // NewSheddingStat returns a SheddingStat.
        func NewSheddingStat(name string) *SheddingStat {
            st := &SheddingStat{
                name: name,
            }
            go st.run()
            return st
        }
    ```
    
     + <span id="SheddingStat.run">SheddingStat.run()</span>
    ```go
    // 这个方法主要是判断是否过载了，每一分钟重置一次 
    func (s *SheddingStat) run() {
            ticker := time.NewTicker(time.Minute)
            defer ticker.Stop()
            for range ticker.C {
                c := stat.CpuUsage()
                st := s.reset()
                if st.Drop == 0 {
                    logx.Statf("(%s) shedding_stat [1m], cpu: %d, total: %d, pass: %d, drop: %d",
                        s.name, c, st.Total, st.Pass, st.Drop)
                } else {
                    logx.Statf("(%s) shedding_stat_drop [1m], cpu: %d, total: %d, pass: %d, drop: %d",
                        s.name, c, st.Total, st.Pass, st.Drop)
                }
            }
        }
    ```
    
## 接下来是要检查 cpu 负荷
github.com/tal-tech/go-zero/core/stat/usage.go 这个文件的 init() 方法
```go
func init() {
	go func() {
		cpuTicker := time.NewTicker(cpuRefreshInterval)
		defer cpuTicker.Stop()
		allTicker := time.NewTicker(allRefreshInterval)
		defer allTicker.Stop()

		for {
			select {
			case <-cpuTicker.C:
				threading.RunSafe(func() {
				                // RefreshCpu方法主要做的是计算 (进程所占用的 CPU 时间) / (系统 CPU 总运行时间) (百分比)
					curUsage := internal.RefreshCpu()
					prevUsage := atomic.LoadInt64(&cpuUsage)
					// cpu = cpuᵗ⁻¹ * beta + cpuᵗ * (1 - beta)
					// 计算上一次进程所占用的时间比 和 这次系统所占用的时间比的和
					usage := int64(float64(prevUsage)*beta + float64(curUsage)*(1-beta))
					atomic.StoreInt64(&cpuUsage, usage)
				})
			case <-allTicker.C:
				printUsage()
			}
		}
	}()
}
```
这个方法有个定时器 250ms 运行一次，更新 cpu负荷，跟新负荷的这个包里也有一个 init() 方法，如下:
```go
// if /proc not present, ignore the cpu calcuation, like wsl linux
func init() {
	cpus, err := perCpuUsage()
	if err != nil {
		logx.Error(err)
		return
	}

	cores = uint64(len(cpus))
	// 获取 cpu 的核数，如果是8: 0-7  sets 是一个数据
	sets, err := cpuSets()
	if err != nil {
		logx.Error(err)
		return
	}

	quota = float64(len(sets))
	// 取的是 cpu.cfs_quota_us 这个里面的数据
	cq, err := cpuQuota()
	if err == nil {
		if cq != -1 {// cq=-1 表示不做限制
		    // 实际上取的是 cpu.cfs_period_us 这个文件里的数据
			period, err := cpuPeriod()
			if err != nil {
				logx.Error(err)
				return
			}
            // cpu.cfs_period_us：cpu分配的周期(微秒），默认为100000。
            // cpu.cfs_quota_us：表示该control group限制占用的时间（微秒），默认为-1，表示不限制。如果设为50000，表示占用50000/10000=50%的CPU。
			limit := float64(cq) / float64(period)
			if limit < quota {
			    // 把限制设置成 系统设置成的限制
				quota = limit
			}
		}
	}
    // 每 100ms CPU花费的时间
	preSystem, err = systemCpuUsage()
	if err != nil {
		logx.Error(err)
		return
	}
    // 统计 任务组所有任务消耗的总 CPU 时间
	preTotal, err = totalCpuUsage()
	if err != nil {
		logx.Error(err)
		return
	}
}
```
 - 上面方法中的 `perCpuUsage()` 方法调用的 `currentCgroup()`, 这个方法的作用如下: 
      + 读取当前 go进程的 /proc/[进程ID]/cgroup, 这个文件主要是控制进程的系统占用资源
      + 从上面的文件中读取以 cpu 开头的项目
      + 拼接路径 `/sys/fs/cgroup/%s` %s是上面获取到的 cpu开头的项目 
      + 最后返回 `&cgroup{cgroups: cgroups}, nil`
      + 实际上找的是 /sys/fs/cgroup/cpuacct/cpuacct.usage_percpu 这个文件里的数据
        - 这个文件里的数据实际上保存的是 所有任务在每一个cpu上分别消耗的cpu时间(纳秒)
      





    
